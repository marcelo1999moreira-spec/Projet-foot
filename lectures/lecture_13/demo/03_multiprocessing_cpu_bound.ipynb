{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Multiprocessing & CPU-Bound Tasks\n",
    "\n",
    "## Topic 3: True Parallelism for Heavy Computation\n",
    "\n",
    "In this notebook, we'll explore:\n",
    "1. Why threads fail for CPU-bound tasks\n",
    "2. `ProcessPoolExecutor` for true parallelism\n",
    "3. Monte Carlo option pricing in parallel\n",
    "4. Chunking to reduce overhead\n",
    "5. Portfolio Value-at-Risk (VaR) calculation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_cores = os.cpu_count()\n",
    "print(f\"This machine has {n_cores} CPU cores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Why Threads Fail for CPU-Bound Tasks\n",
    "\n",
    "Let's see the GIL in action. We'll run a CPU-intensive task and compare threads vs processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_intensive_task(n):\n",
    "    \"\"\"\n",
    "    A CPU-intensive task: compute sum of squares.\n",
    "    This keeps the CPU busy with calculations.\n",
    "    \"\"\"\n",
    "    total = 0.0\n",
    "    for i in range(n):\n",
    "        total += i * i * np.sin(i) * np.cos(i)\n",
    "    return total\n",
    "\n",
    "# Test the function\n",
    "start = time.time()\n",
    "result = cpu_intensive_task(1_000_000)\n",
    "print(f\"Single task time: {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple CPU-intensive tasks\n",
    "n_tasks = 4\n",
    "task_size = 2_000_000\n",
    "\n",
    "print(f\"Running {n_tasks} CPU-intensive tasks...\\n\")\n",
    "\n",
    "# Sequential\n",
    "start = time.time()\n",
    "sequential_results = [cpu_intensive_task(task_size) for _ in range(n_tasks)]\n",
    "seq_time = time.time() - start\n",
    "print(f\"Sequential:     {seq_time:.2f}s\")\n",
    "\n",
    "# Threading (will NOT help due to GIL)\n",
    "start = time.time()\n",
    "with ThreadPoolExecutor(max_workers=n_tasks) as executor:\n",
    "    thread_results = list(executor.map(lambda _: cpu_intensive_task(task_size), range(n_tasks)))\n",
    "thread_time = time.time() - start\n",
    "print(f\"Threading:      {thread_time:.2f}s (speedup: {seq_time/thread_time:.2f}x)\")\n",
    "\n",
    "# Multiprocessing (WILL help - bypasses GIL)\n",
    "start = time.time()\n",
    "with ProcessPoolExecutor(max_workers=n_tasks) as executor:\n",
    "    process_results = list(executor.map(cpu_intensive_task, [task_size] * n_tasks))\n",
    "process_time = time.time() - start\n",
    "print(f\"Multiprocessing: {process_time:.2f}s (speedup: {seq_time/process_time:.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observation\n",
    "\n",
    "- **Threading**: No speedup (or even slower!) because the GIL prevents true parallel execution\n",
    "- **Multiprocessing**: Near-linear speedup because each process has its own Python interpreter and GIL\n",
    "\n",
    "**Rule**: For CPU-bound work, always use `ProcessPoolExecutor`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Monte Carlo Option Pricing\n",
    "\n",
    "Monte Carlo simulation is the bread and butter of quantitative finance. Let's parallelize it!\n",
    "\n",
    "### Black-Scholes-Merton Model\n",
    "\n",
    "Under risk-neutral pricing, the stock price at maturity is:\n",
    "\n",
    "$$S_T = S_0 \\exp\\left[\\left(r - \\frac{\\sigma^2}{2}\\right)T + \\sigma\\sqrt{T}Z\\right]$$\n",
    "\n",
    "Where $Z \\sim N(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_option_batch(args):\n",
    "    \"\"\"\n",
    "    Price a European call option using Monte Carlo simulation.\n",
    "    \n",
    "    This function is designed for parallel execution - it takes a single\n",
    "    tuple of arguments and returns the average payoff for a batch of simulations.\n",
    "    \"\"\"\n",
    "    S0, K, T, r, sigma, n_paths, seed = args\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate random paths\n",
    "    Z = np.random.standard_normal(n_paths)\n",
    "    \n",
    "    # Simulate terminal stock prices\n",
    "    ST = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z)\n",
    "    \n",
    "    # Calculate payoffs\n",
    "    payoffs = np.maximum(ST - K, 0)\n",
    "    \n",
    "    # Return discounted average payoff\n",
    "    return np.exp(-r * T) * np.mean(payoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option parameters\n",
    "S0 = 100      # Current stock price\n",
    "K = 100       # Strike price (at-the-money)\n",
    "T = 1.0       # 1 year to maturity\n",
    "r = 0.05      # 5% risk-free rate\n",
    "sigma = 0.2   # 20% volatility\n",
    "\n",
    "# Simulation parameters\n",
    "total_paths = 4_000_000  # Total number of Monte Carlo paths\n",
    "n_batches = 8            # Split into batches for parallel processing\n",
    "paths_per_batch = total_paths // n_batches\n",
    "\n",
    "print(f\"Total paths: {total_paths:,}\")\n",
    "print(f\"Batches: {n_batches}\")\n",
    "print(f\"Paths per batch: {paths_per_batch:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare arguments for each batch\n",
    "batch_args = [\n",
    "    (S0, K, T, r, sigma, paths_per_batch, seed) \n",
    "    for seed in range(n_batches)\n",
    "]\n",
    "\n",
    "# Sequential execution\n",
    "print(\"Sequential execution:\")\n",
    "start = time.time()\n",
    "sequential_prices = [monte_carlo_option_batch(args) for args in batch_args]\n",
    "seq_time = time.time() - start\n",
    "seq_price = np.mean(sequential_prices)\n",
    "print(f\"  Time: {seq_time:.2f}s\")\n",
    "print(f\"  Option Price: ${seq_price:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel execution\n",
    "print(\"\\nParallel execution:\")\n",
    "start = time.time()\n",
    "with ProcessPoolExecutor(max_workers=n_cores) as executor:\n",
    "    parallel_prices = list(executor.map(monte_carlo_option_batch, batch_args))\n",
    "par_time = time.time() - start\n",
    "par_price = np.mean(parallel_prices)\n",
    "print(f\"  Time: {par_time:.2f}s\")\n",
    "print(f\"  Option Price: ${par_price:.4f}\")\n",
    "print(f\"  Speedup: {seq_time/par_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with Black-Scholes analytical solution\n",
    "from scipy.stats import norm\n",
    "\n",
    "def black_scholes_call(S0, K, T, r, sigma):\n",
    "    \"\"\"Analytical Black-Scholes price for European call option.\"\"\"\n",
    "    d1 = (np.log(S0/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma*np.sqrt(T)\n",
    "    return S0*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)\n",
    "\n",
    "bs_price = black_scholes_call(S0, K, T, r, sigma)\n",
    "print(f\"\\nBlack-Scholes analytical price: ${bs_price:.4f}\")\n",
    "print(f\"Monte Carlo estimate: ${par_price:.4f}\")\n",
    "print(f\"Error: ${abs(par_price - bs_price):.4f} ({abs(par_price - bs_price)/bs_price*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: When Parallelization Hurts - The Overhead Trap\n",
    "\n",
    "Parallelization has overhead (creating processes, copying data). If tasks are too small, the overhead dominates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_task(x):\n",
    "    \"\"\"A very small task - just multiply.\"\"\"\n",
    "    return x * x\n",
    "\n",
    "def small_task(x):\n",
    "    \"\"\"A small task - some computation.\"\"\"\n",
    "    return sum(i * i for i in range(1000))\n",
    "\n",
    "def medium_task(x):\n",
    "    \"\"\"A medium task - more computation.\"\"\"\n",
    "    return sum(i * i for i in range(100_000))\n",
    "\n",
    "def large_task(x):\n",
    "    \"\"\"A large task - substantial computation.\"\"\"\n",
    "    return sum(i * i for i in range(1_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = 100\n",
    "items = list(range(n_items))\n",
    "\n",
    "results = []\n",
    "\n",
    "for task_name, task_func in [('tiny', tiny_task), ('small', small_task), \n",
    "                              ('medium', medium_task), ('large', large_task)]:\n",
    "    # Sequential\n",
    "    start = time.time()\n",
    "    _ = [task_func(x) for x in items]\n",
    "    seq_time = time.time() - start\n",
    "    \n",
    "    # Parallel\n",
    "    start = time.time()\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        _ = list(executor.map(task_func, items))\n",
    "    par_time = time.time() - start\n",
    "    \n",
    "    speedup = seq_time / par_time\n",
    "    results.append({\n",
    "        'Task': task_name,\n",
    "        'Sequential (s)': seq_time,\n",
    "        'Parallel (s)': par_time,\n",
    "        'Speedup': speedup,\n",
    "        'Verdict': 'Use parallel' if speedup > 1.5 else 'Stay sequential'\n",
    "    })\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lesson\n",
    "\n",
    "- **Tiny tasks**: Parallel is SLOWER (overhead dominates)\n",
    "- **Small tasks**: Might be slower or break even\n",
    "- **Medium/Large tasks**: Parallel wins!\n",
    "\n",
    "**Rule of thumb**: Each task should take at least 10-100ms to justify parallelization overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Chunking\n",
    "\n",
    "If you have many small tasks, group them into larger chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk):\n",
    "    \"\"\"Process a chunk of items together.\"\"\"\n",
    "    return [small_task(x) for x in chunk]\n",
    "\n",
    "# Create chunks\n",
    "n_items = 1000\n",
    "items = list(range(n_items))\n",
    "chunk_size = 250\n",
    "chunks = [items[i:i+chunk_size] for i in range(0, n_items, chunk_size)]\n",
    "\n",
    "print(f\"Total items: {n_items}\")\n",
    "print(f\"Chunk size: {chunk_size}\")\n",
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential (item by item)\n",
    "start = time.time()\n",
    "_ = [small_task(x) for x in items]\n",
    "seq_time = time.time() - start\n",
    "print(f\"Sequential: {seq_time:.3f}s\")\n",
    "\n",
    "# Parallel (item by item) - bad!\n",
    "start = time.time()\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    _ = list(executor.map(small_task, items))\n",
    "par_bad_time = time.time() - start\n",
    "print(f\"Parallel (item by item): {par_bad_time:.3f}s (speedup: {seq_time/par_bad_time:.2f}x)\")\n",
    "\n",
    "# Parallel (chunked) - good!\n",
    "start = time.time()\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    chunk_results = list(executor.map(process_chunk, chunks))\n",
    "# Flatten results\n",
    "_ = [item for chunk in chunk_results for item in chunk]\n",
    "par_good_time = time.time() - start\n",
    "print(f\"Parallel (chunked): {par_good_time:.3f}s (speedup: {seq_time/par_good_time:.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Portfolio Value-at-Risk (VaR)\n",
    "\n",
    "VaR is a fundamental risk measure in finance. Monte Carlo VaR is computationally intensive and perfect for parallelization.\n",
    "\n",
    "**VaR**: The maximum expected loss at a given confidence level over a specific time horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample portfolio\n",
    "np.random.seed(42)\n",
    "\n",
    "# Portfolio: 5 stocks with different expected returns and volatilities\n",
    "assets = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']\n",
    "weights = np.array([0.25, 0.20, 0.25, 0.15, 0.15])  # Portfolio weights\n",
    "expected_returns = np.array([0.12, 0.10, 0.11, 0.15, 0.20])  # Annual returns\n",
    "volatilities = np.array([0.25, 0.22, 0.20, 0.30, 0.50])  # Annual volatility\n",
    "\n",
    "# Correlation matrix (simplified)\n",
    "correlation = np.array([\n",
    "    [1.0, 0.6, 0.7, 0.5, 0.3],\n",
    "    [0.6, 1.0, 0.8, 0.6, 0.4],\n",
    "    [0.7, 0.8, 1.0, 0.5, 0.3],\n",
    "    [0.5, 0.6, 0.5, 1.0, 0.5],\n",
    "    [0.3, 0.4, 0.3, 0.5, 1.0]\n",
    "])\n",
    "\n",
    "# Covariance matrix\n",
    "cov_matrix = np.outer(volatilities, volatilities) * correlation\n",
    "\n",
    "portfolio_value = 1_000_000  # $1 million portfolio\n",
    "time_horizon = 10  # 10 trading days\n",
    "confidence_level = 0.95  # 95% VaR\n",
    "\n",
    "print(\"Portfolio:\")\n",
    "for asset, weight in zip(assets, weights):\n",
    "    print(f\"  {asset}: {weight*100:.0f}%\")\n",
    "print(f\"\\nTotal Value: ${portfolio_value:,}\")\n",
    "print(f\"Time Horizon: {time_horizon} days\")\n",
    "print(f\"Confidence Level: {confidence_level*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_portfolio_returns(args):\n",
    "    \"\"\"\n",
    "    Simulate portfolio returns over the time horizon.\n",
    "    Returns the portfolio values at the end of the horizon.\n",
    "    \"\"\"\n",
    "    weights, expected_returns, cov_matrix, n_sims, time_horizon, seed = args\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    n_assets = len(weights)\n",
    "    \n",
    "    # Daily parameters (assuming 252 trading days per year)\n",
    "    daily_returns = expected_returns / 252\n",
    "    daily_cov = cov_matrix / 252\n",
    "    \n",
    "    # Cholesky decomposition for correlated random numbers\n",
    "    L = np.linalg.cholesky(daily_cov)\n",
    "    \n",
    "    # Simulate returns for each day and each simulation\n",
    "    portfolio_returns = np.zeros(n_sims)\n",
    "    \n",
    "    for sim in range(n_sims):\n",
    "        cumulative_return = 1.0\n",
    "        for day in range(time_horizon):\n",
    "            # Generate correlated random returns\n",
    "            Z = np.random.standard_normal(n_assets)\n",
    "            asset_returns = daily_returns + L @ Z\n",
    "            \n",
    "            # Portfolio return for this day\n",
    "            portfolio_daily_return = np.dot(weights, asset_returns)\n",
    "            cumulative_return *= (1 + portfolio_daily_return)\n",
    "        \n",
    "        portfolio_returns[sim] = cumulative_return - 1  # Total return over horizon\n",
    "    \n",
    "    return portfolio_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "total_simulations = 100_000\n",
    "n_batches = 8\n",
    "sims_per_batch = total_simulations // n_batches\n",
    "\n",
    "print(f\"Total simulations: {total_simulations:,}\")\n",
    "print(f\"Batches: {n_batches}\")\n",
    "print(f\"Simulations per batch: {sims_per_batch:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare batch arguments\n",
    "batch_args = [\n",
    "    (weights, expected_returns, cov_matrix, sims_per_batch, time_horizon, seed)\n",
    "    for seed in range(n_batches)\n",
    "]\n",
    "\n",
    "# Sequential execution\n",
    "print(\"Sequential VaR calculation:\")\n",
    "start = time.time()\n",
    "seq_returns = [simulate_portfolio_returns(args) for args in batch_args]\n",
    "seq_returns = np.concatenate(seq_returns)\n",
    "seq_time = time.time() - start\n",
    "print(f\"  Time: {seq_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel execution\n",
    "print(\"\\nParallel VaR calculation:\")\n",
    "start = time.time()\n",
    "with ProcessPoolExecutor(max_workers=n_cores) as executor:\n",
    "    par_returns = list(executor.map(simulate_portfolio_returns, batch_args))\n",
    "par_returns = np.concatenate(par_returns)\n",
    "par_time = time.time() - start\n",
    "print(f\"  Time: {par_time:.2f}s\")\n",
    "print(f\"  Speedup: {seq_time/par_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VaR\n",
    "var_95 = np.percentile(par_returns, (1 - confidence_level) * 100) * portfolio_value\n",
    "var_99 = np.percentile(par_returns, 1) * portfolio_value\n",
    "cvar_95 = par_returns[par_returns <= np.percentile(par_returns, 5)].mean() * portfolio_value\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"RISK METRICS (10-day horizon)\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"95% VaR:  ${-var_95:,.0f} ({-var_95/portfolio_value*100:.2f}%)\")\n",
    "print(f\"99% VaR:  ${-var_99:,.0f} ({-var_99/portfolio_value*100:.2f}%)\")\n",
    "print(f\"95% CVaR: ${-cvar_95:,.0f} ({-cvar_95/portfolio_value*100:.2f}%)\")\n",
    "print(f\"\\nInterpretation: With 95% confidence, the portfolio will not\")\n",
    "print(f\"lose more than ${-var_95:,.0f} over the next 10 trading days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the return distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of returns\n",
    "ax1 = axes[0]\n",
    "ax1.hist(par_returns * 100, bins=100, density=True, alpha=0.7, color='steelblue', edgecolor='white')\n",
    "ax1.axvline(var_95/portfolio_value * 100, color='red', linestyle='--', linewidth=2, label=f'95% VaR: {var_95/portfolio_value*100:.2f}%')\n",
    "ax1.axvline(var_99/portfolio_value * 100, color='darkred', linestyle='--', linewidth=2, label=f'99% VaR: {var_99/portfolio_value*100:.2f}%')\n",
    "ax1.axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "ax1.set_xlabel('Portfolio Return (%)')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Distribution of 10-Day Portfolio Returns')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Left tail (losses)\n",
    "ax2 = axes[1]\n",
    "losses = par_returns[par_returns < 0] * portfolio_value\n",
    "ax2.hist(losses, bins=50, density=True, alpha=0.7, color='coral', edgecolor='white')\n",
    "ax2.axvline(var_95, color='red', linestyle='--', linewidth=2, label=f'95% VaR: ${-var_95:,.0f}')\n",
    "ax2.axvline(var_99, color='darkred', linestyle='--', linewidth=2, label=f'99% VaR: ${-var_99:,.0f}')\n",
    "ax2.set_xlabel('Portfolio Loss ($)')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('Distribution of Losses (Left Tail)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Multiprocessing for CPU-Bound Tasks\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Use `ProcessPoolExecutor` for CPU-bound work** - bypasses the GIL\n",
    "\n",
    "2. **Threading fails for CPU tasks** - the GIL prevents parallel execution\n",
    "\n",
    "3. **Watch out for overhead** - tasks should be substantial (>10ms)\n",
    "\n",
    "4. **Chunking helps** - group small tasks into larger batches\n",
    "\n",
    "5. **Functions must be picklable** - no lambdas, no nested functions\n",
    "\n",
    "### Finance Applications\n",
    "\n",
    "| Application | Why It's CPU-Bound |\n",
    "|-------------|--------------------|\n",
    "| Monte Carlo pricing | Millions of path simulations |\n",
    "| VaR calculations | Many portfolio scenarios |\n",
    "| Backtesting | Test strategy over long history |\n",
    "| Optimization | Evaluate objective function many times |\n",
    "| Bootstrap inference | Resample and calculate statistics |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: European Put Option\n",
    "\n",
    "Modify the Monte Carlo option pricing code to price a European put option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def monte_carlo_put_batch(args):\n",
    "    \"\"\"Price a European put option using Monte Carlo.\"\"\"\n",
    "    pass  # Implement me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Optimal Chunk Size\n",
    "\n",
    "Experiment with different chunk sizes for the small_task example. Find the optimal chunk size for your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Try chunk sizes: 10, 50, 100, 250, 500, 1000\n",
    "# Measure execution time for each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Asian Option Pricing\n",
    "\n",
    "Price an Asian call option (payoff based on average price over the life of the option) using parallel Monte Carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: You'll need to simulate the full price path, not just the terminal price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
